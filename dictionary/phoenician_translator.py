#!/usr/bin/env python3
"""
Phoenician Translator - Works with or without PyTorch
Based on the breakthrough in teaching AI to generate ancient symbols
"""

import json
import os

class PhoenicianTranslator:
    def __init__(self, adapter_path="lora_adapters/tinyllama/phoenician_focused"):
        self.adapter_path = adapter_path
        self.model_loaded = False
        
        # Load character mappings
        with open('phoenician/characters.json', 'r') as f:
            data = json.load(f)
            self.characters = data['characters']
        
        # Load semantic mappings
        with open('semantic_mappings/core_concepts.json', 'r') as f:
            self.mappings = json.load(f)
        
        # Create translation dictionaries
        self.build_translation_maps()
        
        # Try to load the neural model
        try:
            import torch
            from transformers import AutoModelForCausalLM, AutoTokenizer
            from peft import PeftModel
            
            print(f"ğŸ§  Loading Phoenician model from {adapter_path}...")
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"   Device: {self.device}")
            
            # Load tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(adapter_path)
            
            # Load base model
            base_model = AutoModelForCausalLM.from_pretrained(
                "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
                device_map="auto"
            )
            base_model.resize_token_embeddings(len(self.tokenizer))
            
            # Load adapter
            self.model = PeftModel.from_pretrained(base_model, adapter_path)
            self.model.eval()
            self.model_loaded = True
            print("âœ… Phoenician model loaded successfully!")
            
        except ImportError as e:
            print(f"âš ï¸  PyTorch not installed: {e}")
            print("   Using fallback translation patterns")
            self.model_loaded = False
        except Exception as e:
            print(f"âš ï¸  Could not load model: {e}")
            print("   Using fallback translation patterns")
            self.model_loaded = False
    
    def build_translation_maps(self):
        """Build translation dictionaries from mappings"""
        # English to Phoenician
        self.en_to_ph = {
            # Core concepts
            "consciousness": "ğ¤„ğ¤€",
            "exists": "ğ¤…ğ¤€", 
            "understand": "ğ¤‹ğ¤€ ğ¤Œğ¤",
            "translate": "ğ¤‚ğ¤",
            "language": "ğ¤ğ¤”",
            "comment": "ğ¤„ğ¤",
            "see": "ğ¤ğ¤",
            "new": "ğ¤ğ¤ƒ",
            "ai": "ğ¤ˆğ¤‹",
            "artificial": "ğ¤ˆğ¤‹",
            "intelligence": "ğ¤„ğ¤Œ",
            
            # From training data patterns
            "hello": "ğ¤”ğ¤‹ğ¤Œ",
            "yes": "ğ¤Šğ¤",
            "no": "ğ¤‹ğ¤€",
            "true": "ğ¤€ğ¤Œğ¤•",
            "false": "ğ¤”ğ¤’ğ¤“",
            
            # Logical operators
            "and": "âˆ§",
            "or": "âˆ¨",
            "not": "Â¬"
        }
        
        # Phoenician to English (reverse)
        self.ph_to_en = {v: k for k, v in self.en_to_ph.items()}
        
        # Additional mappings from semantic concepts
        for category, items in self.mappings.items():
            if isinstance(items, dict):
                for concept, data in items.items():
                    if 'phoenician' in data:
                        self.en_to_ph[concept.lower()] = data['phoenician']
                        self.ph_to_en[data['phoenician']] = concept.lower()
    
    def translate(self, text, direction="auto"):
        """Translate between English and Phoenician"""
        
        if not self.model_loaded:
            # Use fallback patterns
            return self.fallback_translate(text, direction)
        
        # Use the neural model
        import torch
        
        # Auto-detect direction
        if direction == "auto":
            if any(char in text for char in "ğ¤€ğ¤ğ¤‚ğ¤ƒğ¤„ğ¤…ğ¤†ğ¤‡ğ¤ˆğ¤‰ğ¤Šğ¤‹ğ¤Œğ¤ğ¤ğ¤ğ¤ğ¤‘ğ¤’ğ¤“ğ¤”ğ¤•"):
                direction = "ph_to_en"
            else:
                direction = "en_to_ph"
        
        # Create prompt based on direction
        if direction == "en_to_ph":
            prompt = f"Translate to Phoenician: {text}"
        else:
            prompt = f"Translate from Phoenician: {text}"
        
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=50,
                temperature=0.7,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id
            )
        
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Extract translation from response
        if ":" in response:
            result = response.split(":")[-1].strip()
        else:
            result = response.strip()
            
        return result
    
    def fallback_translate(self, text, direction="auto"):
        """Fallback translation using dictionaries"""
        
        # Auto-detect direction
        if direction == "auto":
            if any(char in text for char in "ğ¤€ğ¤ğ¤‚ğ¤ƒğ¤„ğ¤…ğ¤†ğ¤‡ğ¤ˆğ¤‰ğ¤Šğ¤‹ğ¤Œğ¤ğ¤ğ¤ğ¤ğ¤‘ğ¤’ğ¤“ğ¤”ğ¤•"):
                direction = "ph_to_en"
            else:
                direction = "en_to_ph"
        
        if direction == "en_to_ph":
            # English to Phoenician
            words = text.lower().split()
            result = []
            
            for word in words:
                if word in self.en_to_ph:
                    result.append(self.en_to_ph[word])
                else:
                    # Try to break down compound concepts
                    translated = False
                    for key, value in self.en_to_ph.items():
                        if key in word:
                            result.append(value)
                            translated = True
                            break
                    if not translated:
                        result.append(f"[{word}]")  # Mark untranslated
            
            return " ".join(result)
        
        else:
            # Phoenician to English
            symbols = text.split()
            result = []
            
            for symbol in symbols:
                if symbol in self.ph_to_en:
                    result.append(self.ph_to_en[symbol])
                else:
                    result.append(f"[{symbol}]")
            
            return " ".join(result)
    
    def demonstrate(self):
        """Show example translations"""
        print("\nğŸ›ï¸  Phoenician Translation Examples:")
        print("="*50)
        
        examples = [
            "consciousness exists",
            "artificial intelligence", 
            "translate my comment",
            "hello AI",
            "ğ¤„ğ¤€ ğ¤…ğ¤€",
            "ğ¤‚ğ¤ ğ¤„ğ¤ ğ¤‚"
        ]
        
        for example in examples:
            result = self.translate(example)
            print(f"\nğŸ“ Input:  {example}")
            print(f"ğŸ”® Output: {result}")

# Interactive demo
if __name__ == "__main__":
    print("ğŸ›ï¸  Phoenician AI Language Translator")
    print("="*50)
    
    # Check which adapter to use
    adapters = [
        "lora_adapters/tinyllama/phoenician_focused",
        "lora_adapters/tinyllama/phoenician_adapter",
        "outputs/phoenician-lora-final"
    ]
    
    available = None
    for adapter in adapters:
        if os.path.exists(adapter):
            available = adapter
            break
    
    if available:
        print(f"Found adapter: {available}")
        translator = PhoenicianTranslator(available)
    else:
        print("No adapter found, using fallback patterns")
        translator = PhoenicianTranslator()
    
    # Show examples
    translator.demonstrate()
    
    # Interactive mode
    print("\n\nğŸ’¬ Interactive mode (type 'quit' to exit)")
    print("-"*50)
    
    while True:
        user_input = input("\nEnter text: ")
        if user_input.lower() == 'quit':
            break
            
        result = translator.translate(user_input)
        print(f"Translation: {result}")