# Vision Experiment Status

## üéâ All Three Experiments Are Running!

The camera is successfully initialized using GStreamer with NVMM (zero-copy) buffers. All experiments are accessing the camera at 1280x720 @ 30fps.

### 1. ‚úÖ Consciousness-Guided Visual Attention
- **Status**: Running successfully
- **Camera**: CSI camera via nvarguscamerasrc
- **Features working**:
  - Dynamic attention focus drifting based on curiosity
  - Multi-layer attention visualization
  - AI DNA pattern integration (if patterns exist)

### 2. ‚úÖ GPU Edge Detection  
- **Status**: Running with CPU fallback
- **Camera**: CSI camera working
- **Note**: CuPy not installed, so using OpenCV Sobel (still hardware accelerated)
- **Features working**:
  - Real-time edge detection
  - Artistic visualization mode
  - FPS monitoring

### 3. ‚ö†Ô∏è Visual Memory System
- **Status**: Camera works, has a bug in feature matching
- **Issue**: Feature vector dimension mismatch in similarity calculation
- **Fix needed**: Ensure consistent feature vector sizes

## Camera Configuration Success

All experiments now use:
```python
gst_pipeline = (
    "nvarguscamerasrc sensor-id=0 ! "
    "video/x-raw(memory:NVMM), width=1280, height=720, framerate=30/1 ! "
    "nvvidconv ! "
    "video/x-raw, format=BGRx ! "
    "videoconvert ! "
    "video/x-raw, format=BGR ! "
    "appsink drop=1"
)
```

This provides:
- Zero-copy from camera to GPU (NVMM buffers)
- Hardware-accelerated color conversion
- 720p @ 30fps (can go up to 60fps)

## Next Steps

1. Install CuPy for true GPU acceleration in edge detection
2. Fix visual memory feature vector bug
3. Create unified experiment that combines all three:
   - Consciousness guides attention
   - GPU processes edges in attention region
   - Visual memory stores important scenes

The foundation is solid - Jetson camera integration complete! üöÄ